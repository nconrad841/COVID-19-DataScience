{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One run full walkthrough\n",
    "* Do the full walkthorugh on the large data set\n",
    "* Refactor the source code and bring it to the individual scripts\n",
    "* Ensure a full run with one click"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : b'From https://github.com/CSSEGISandData/COVID-19\\n   67b87f29..29b85c49  master     -> origin/master\\n   2c3745fe..0fa72232  web-data   -> origin/web-data\\n'\n",
      "out : b'Updating 67b87f29..29b85c49\\nFast-forward\\n csse_covid_19_data/README.md                       |    3 +\\n .../csse_covid_19_daily_reports/09-10-2020.csv     | 3955 ++++++++++++\\n .../csse_covid_19_daily_reports/09-11-2020.csv     | 3955 ++++++++++++\\n .../csse_covid_19_daily_reports/09-12-2020.csv     | 3955 ++++++++++++\\n .../csse_covid_19_daily_reports/09-13-2020.csv     | 3955 ++++++++++++\\n .../csse_covid_19_daily_reports_us/09-10-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/09-11-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/09-12-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/09-13-2020.csv  |   59 +\\n .../time_series_covid19_confirmed_US.csv           | 6682 ++++++++++----------\\n .../time_series_covid19_confirmed_global.csv       |  534 +-\\n .../time_series_covid19_deaths_US.csv              | 6682 ++++++++++----------\\n .../time_series_covid19_deaths_global.csv          |  534 +-\\n .../time_series_covid19_recovered_global.csv       |  508 +-\\n 14 files changed, 23529 insertions(+), 7470 deletions(-)\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/09-10-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/09-11-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/09-12-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/09-13-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/09-10-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/09-11-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/09-12-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/09-13-2020.csv\\n'\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/data/get_data.py\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_johns_hopkins():\n",
    "    ''' Get data by a git pull request, the source code has to be pulled first\n",
    "        Result is stored in the predifined csv structure\n",
    "    '''\n",
    "    git_pull = subprocess.Popen( \"/usr/bin/git pull\" ,\n",
    "                         cwd = os.path.dirname( '../data/raw/COVID-19/' ),\n",
    "                         shell = True,\n",
    "                         stdout = subprocess.PIPE,\n",
    "                         stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "\n",
    "def get_current_data_germany():\n",
    "    ''' Get current data from germany, attention API endpoint not too stable\n",
    "        Result data frame is stored as pd.DataFrame\n",
    "\n",
    "    '''\n",
    "    # 16 states\n",
    "    #data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/Coronaf%C3%A4lle_in_den_Bundesl%C3%A4ndern/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    # 400 regions / Landkreise\n",
    "    data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/RKI_Landkreisdaten/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    json_object=json.loads(data.content)\n",
    "    full_list=[]\n",
    "    for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "\n",
    "    pd_full_list=pd.DataFrame(full_list)\n",
    "    pd_full_list.to_csv('../data/raw/NPGEO/GER_state_data.csv',sep=';')\n",
    "    print(' Number of regions rows: '+str(pd_full_list.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins()\n",
    "    #get_current_data_germany()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Process pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows stored: 62776\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/data/process_JH_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def store_relational_JH_data():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path = '../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw = pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base = pd_raw.rename(columns={'Country/Region':'country',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state'] = pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base = pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model = pd_data_base.set_index(['state','country']) \\\n",
    "                                .T                              \\\n",
    "                                .stack(level=[0,1])             \\\n",
    "                                .reset_index()                  \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                   0:'confirmed'},\n",
    "                                                  )\n",
    "\n",
    "    pd_relational_model['date'] = pd_relational_model.date.astype('datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv('../data/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: ' + str(pd_relational_model.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    store_relational_JH_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Filter and Doubling Rate & SIR Model calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/features/build_features.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "\n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           window, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "\n",
    "    pd_filtered_result=df_output[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    #print('--+++ after group by apply')\n",
    "    #print(pd_filtered_result[pd_filtered_result['country']=='Germany'].tail())\n",
    "\n",
    "    #df_output=pd.merge(df_output,pd_filtered_result[['index',str(filter_on+'_filtered')]],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    #print(df_output[df_output['country']=='Germany'].tail())\n",
    "    return df_output.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','country']).apply(rolling_reg,filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SIR_model_t(SIR, t, beta, gamma):\n",
    "    ''' Simple SIR model\n",
    "        S: susceptible population\n",
    "        t: time step, mandatory for integral.odeint\n",
    "        I: infected people\n",
    "        R: recovered people\n",
    "        beta:\n",
    "\n",
    "        overall condition is that the sum of changes (differnces) sum up to 0\n",
    "        dS+dI+dR=0\n",
    "        S+I+R= N (constant size of population)\n",
    "\n",
    "    '''\n",
    "\n",
    "    S, I, R = SIR\n",
    "    dS_dt = -beta * S * I / N0  # S*I is the\n",
    "    dI_dt = beta * S * I / N0 - gamma * I\n",
    "    dR_dt = gamma * I\n",
    "    return dS_dt, dI_dt, dR_dt\n",
    "\n",
    "def fit_odeint(x, beta, gamma):\n",
    "    '''\n",
    "    helper function for the integration\n",
    "    '''\n",
    "    return integrate.odeint(SIR_model_t, (S0, I0, R0), t, args=(beta, gamma))[:,1] # we only would like to get dI\n",
    "\n",
    "def SIR(data):\n",
    "    popt = [0.4, 0.1]\n",
    "    ydata = data\n",
    "    t = np.arange(len(ydata))\n",
    "    try:\n",
    "        popt, pcov = optimize.curve_fit(fit_odeint, t, ydata, maxfev=5000)\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        \n",
    "        # get the final fitted curve\n",
    "        return fit_odeint(t, *popt)\n",
    "    \n",
    "    except ValueError:\n",
    "        print('RunTimeError')\n",
    "        return [0] * len(ydata)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_JH_data = pd.read_csv('../data/processed/COVID_relational_confirmed.csv', sep=';', parse_dates=[0])\n",
    "pd_JH_data = pd_JH_data.sort_values('date', ascending=True).copy()\n",
    "pd_JH_data.drop('state', axis=1, inplace=True)\n",
    "\n",
    "# Create new Frame\n",
    "newFrame = pd.DataFrame()\n",
    "for col in pd_JH_data.columns:\n",
    "    newFrame[col] = ''    \n",
    "    \n",
    "#if testFrame.reindex(sorted(testFrame.columns), axis=1).columns.all() == newFrame.reindex(sorted(newFrame.columns), axis=1).columns.all():        \n",
    "    \n",
    "for date in pd.unique(pd_JH_data['date']):\n",
    "    for country in pd.unique(pd_JH_data['country']):\n",
    "        singleFrame = pd_JH_data[(pd_JH_data['date'] == date) & (pd_JH_data['country'] ==  country)]\n",
    "        singleFrame            = pd.DataFrame(singleFrame.sum()).T\n",
    "        singleFrame['date']    = date\n",
    "        singleFrame['country'] = country\n",
    "        \n",
    "        newFrame = newFrame.append(singleFrame)\n",
    "\n",
    "newFrame = newFrame.reset_index()        \n",
    "newFrame.to_csv('../data/processed/COVID_relational_confirmed_SIR.csv',sep=';',index=False)\n",
    "\n",
    "pd_JH_data = newFrame.copy()\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Korea, South</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Kosovo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       date       country confirmed\n",
       "0      0 2020-01-22        Canada         0\n",
       "1      0 2020-01-22  Korea, South         1\n",
       "2      0 2020-01-22        Kosovo         0\n",
       "3      0 2020-01-22        Kuwait         0\n",
       "4      0 2020-01-22    Kyrgyzstan         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_JH_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.8/site-packages/scipy/integrate/odepack.py:247: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "<ipython-input-4-b500a10bf243>:17: RuntimeWarning: overflow encountered in double_scalars\n",
      "  dI_dt = beta * S * I / N0 - gamma * I\n",
      "<ipython-input-4-b500a10bf243>:18: RuntimeWarning: overflow encountered in double_scalars\n",
      "  dR_dt = gamma * I\n",
      "<ipython-input-4-b500a10bf243>:16: RuntimeWarning: overflow encountered in double_scalars\n",
      "  dS_dt = -beta * S * I / N0  # S*I is the\n"
     ]
    }
   ],
   "source": [
    "I0 = 27\n",
    "S0 = pow(10, 6)\n",
    "R0 = 0\n",
    "\n",
    "N0 = pow(10, 6)\n",
    "beta = 0.4\n",
    "gamma = 0.1\n",
    "\n",
    "pd_result_SIR = pd_JH_data.copy()\n",
    "pd_result_SIR['SIR_static'] = 0\n",
    "\n",
    "\n",
    "for each in pd.unique(pd_result_SIR['country']):\n",
    "    \n",
    "    #print(each)\n",
    "    \n",
    "    # Extract y data\n",
    "    ydata_SIR = np.array(pd_result_SIR[pd_result_SIR['country'] == each]['confirmed'][35:])            \n",
    "    t = np.arange(len(ydata_SIR))        \n",
    "\n",
    "    # Calc SIR Data\n",
    "    fitted_SIR = SIR(ydata_SIR.copy())    \n",
    "\n",
    "    # Create a new dataframe with SIR data for update function\n",
    "    SIRFrame = pd.DataFrame({'date': pd_result_SIR[pd_result_SIR['country'] == each]['date'][35:]})\n",
    "    SIRFrame['SIR_static'] = fitted_SIR\n",
    "    SIRFrame['country'] = each\n",
    "\n",
    "    pd_result_SIR.update(SIRFrame['SIR_static'])        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>SIR_static</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Korea, South</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Kosovo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       date       country confirmed  SIR_static\n",
       "0      0 2020-01-22        Canada         0         0.0\n",
       "1      0 2020-01-22  Korea, South         1         0.0\n",
       "2      0 2020-01-22        Kosovo         0         0.0\n",
       "3      0 2020-01-22        Kuwait         0         0.0\n",
       "4      0 2020-01-22    Kyrgyzstan         0         0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_result_SIR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_JH_data = pd.read_csv('../data/processed/COVID_relational_confirmed.csv', sep=';', parse_dates=[0])\n",
    "pd_JH_data = pd_JH_data.sort_values('date', ascending=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>SIR_static</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Korea, South</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Kosovo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44363</th>\n",
       "      <td>44363</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>555537</td>\n",
       "      <td>989.831321</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44364</th>\n",
       "      <td>44364</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>95</td>\n",
       "      <td>98.130972</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44365</th>\n",
       "      <td>44365</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>Angola</td>\n",
       "      <td>3388</td>\n",
       "      <td>3477.475411</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44366</th>\n",
       "      <td>44366</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>1344</td>\n",
       "      <td>784.914842</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44367</th>\n",
       "      <td>44367</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>Austria</td>\n",
       "      <td>33159</td>\n",
       "      <td>18230.823150</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44368 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       level_0  index       date              country confirmed    SIR_static  \\\n",
       "0            0      0 2020-01-22               Canada         0      0.000000   \n",
       "1            1      0 2020-01-22         Korea, South         1      0.000000   \n",
       "2            2      0 2020-01-22               Kosovo         0      0.000000   \n",
       "3            3      0 2020-01-22               Kuwait         0      0.000000   \n",
       "4            4      0 2020-01-22           Kyrgyzstan         0      0.000000   \n",
       "...        ...    ...        ...                  ...       ...           ...   \n",
       "44363    44363      0 2020-09-13            Argentina    555537    989.831321   \n",
       "44364    44364      0 2020-09-13  Antigua and Barbuda        95     98.130972   \n",
       "44365    44365      0 2020-09-13               Angola      3388   3477.475411   \n",
       "44366    44366      0 2020-09-13              Andorra      1344    784.914842   \n",
       "44367    44367      0 2020-09-13              Austria     33159  18230.823150   \n",
       "\n",
       "      state  \n",
       "0            \n",
       "1            \n",
       "2            \n",
       "3            \n",
       "4            \n",
       "...     ...  \n",
       "44363        \n",
       "44364        \n",
       "44365        \n",
       "44366        \n",
       "44367        \n",
       "\n",
       "[44368 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_JH_data = pd_result_SIR.copy()\n",
    "pd_JH_data = pd_JH_data.reset_index()\n",
    "#pd_JH_data.drop('index', axis=1, inplace=True)\n",
    "#pd_JH_data.rename(columns={'level_0':'index'})\n",
    "pd_JH_data['state'] = ''\n",
    "pd_JH_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_result_larg = calc_filtered_data(pd_JH_data)\n",
    "pd_result_larg = calc_doubling_rate(pd_result_larg)\n",
    "pd_result_larg = calc_doubling_rate(pd_result_larg, 'confirmed_filtered')\n",
    "\n",
    "mask = pd_result_larg['confirmed'] > 100\n",
    "pd_result_larg['confirmed_filtered_DR'] = pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n",
    "pd_result_larg.to_csv('../data/processed/COVID_final_set.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_result_larg[pd_result_larg['country'] == 'US'][30:].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Visual Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nick/Documents/Data Science/OwnProject/ads_covid-19/notebooks\n",
      "Running on http://127.0.0.1:8050/\n",
      "Debugger PIN: 956-538-988\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "df_input_large = pd.read_csv('../data/processed/COVID_final_set.csv',sep=';')\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    #  Applied Data Science on COVID-19 data\n",
    "\n",
    "    Goal of the project is to teach data science by applying a cross industry standard process,\n",
    "    it covers the full walkthrough of: automated data gathering, data transformations,\n",
    "    filtering and machine learning to approximating the doubling time, and\n",
    "    (static) deployment of responsive dashboard.\n",
    "\n",
    "    '''),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    ## Multi-Select Country for visualization\n",
    "    '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[ {'label':each, 'value':each} for each in df_input_large['country'].unique()],\n",
    "        value=['US', 'Germany', 'Italy'], # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "        ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "    id='doubling_time',\n",
    "    options=[\n",
    "        {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "        {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "        {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "        {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'},\n",
    "        {'label': 'Timeline SIR Model applied', 'value': 'SIR_static'},\n",
    "    ],\n",
    "    value='confirmed',\n",
    "    multi=False\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_window_slope')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "def update_figure(country_list, show_doubling):\n",
    "\n",
    "\n",
    "    if 'doubling_rate' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['country']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date', 'SIR_static']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date', 'SIR_static']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1280,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "\n",
    "                yaxis=my_yaxis\n",
    "        )\n",
    "    }\n",
    "def visualize():\n",
    "    app.run_server(debug=True, use_reloader=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
